# -*- coding: utf-8 -*-
"""aoml5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14y1JLntgsaZVAmUlSeJYC1YAFhXlWri2
"""


import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

df=pd.read_csv('spam.csv',encoding='latin-1')
df.head()

df = df.iloc[:, [0, 1]]
df.columns = ['label', 'text']
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

def clean_text(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\d+', '', text)
    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])
    lemmatizer = WordNetLemmatizer()
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])
    return text

df['cleaned_text'] = df['text'].apply(clean_text)

X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)
X_train_clean, X_test_clean, _, _ = train_test_split(df['cleaned_text'], df['label'], test_size=0.2, random_state=42)

vectorizer = CountVectorizer()
X_train_bow_raw = vectorizer.fit_transform(X_train_raw)
X_test_bow_raw = vectorizer.transform(X_test_raw)
X_train_bow_clean = vectorizer.fit_transform(X_train_clean)
X_test_bow_clean = vectorizer.transform(X_test_clean)

tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf_raw = tfidf_vectorizer.fit_transform(X_train_raw)
X_test_tfidf_raw = tfidf_vectorizer.transform(X_test_raw)
X_train_tfidf_clean = tfidf_vectorizer.fit_transform(X_train_clean)
X_test_tfidf_clean = tfidf_vectorizer.transform(X_test_clean)

models = {
    "Naive Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

for name, model in models.items():
    print(f"Training {name} with BoW (Uncleaned)")
    model.fit(X_train_bow_raw, y_train)
    y_pred = model.predict(X_test_bow_raw)
    print(f"{name} Accuracy (BoW - Uncleaned):", accuracy_score(y_test, y_pred))

    print(f"Training {name} with BoW (Cleaned)")
    model.fit(X_train_bow_clean, y_train)
    y_pred = model.predict(X_test_bow_clean)
    print(f"{name} Accuracy (BoW - Cleaned):", accuracy_score(y_test, y_pred))

    print(f"Training {name} with TF-IDF (Uncleaned)")
    model.fit(X_train_tfidf_raw, y_train)
    y_pred = model.predict(X_test_tfidf_raw)
    print(f"{name} Accuracy (TF-IDF - Uncleaned):", accuracy_score(y_test, y_pred))

    print(f"Training {name} with TF-IDF (Cleaned)")
    model.fit(X_train_tfidf_clean, y_train)
    y_pred = model.predict(X_test_tfidf_clean)
    print(f"{name} Accuracy (TF-IDF - Cleaned):", accuracy_score(y_test, y_pred))

voting_clf = VotingClassifier(estimators=[
    ('nb', MultinomialNB()),
    ('rf', RandomForestClassifier()),
    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))
], voting='hard')

print("\nTraining Voting Classifier with BoW (Cleaned)")
voting_clf.fit(X_train_bow_clean, y_train)
y_pred = voting_clf.predict(X_test_bow_clean)
print("Voting Classifier Accuracy (BoW - Cleaned):", accuracy_score(y_test, y_pred))

print("\nTraining Voting Classifier with TF-IDF (Cleaned)")
voting_clf.fit(X_train_tfidf_clean, y_train)
y_pred = voting_clf.predict(X_test_tfidf_clean)
print("Voting Classifier Accuracy (TF-IDF - Cleaned):", accuracy_score(y_test, y_pred))

